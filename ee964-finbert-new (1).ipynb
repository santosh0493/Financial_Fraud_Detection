{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0c7a8b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T13:16:52.871771Z",
     "iopub.status.busy": "2025-05-18T13:16:52.871512Z"
    },
    "papermill": {
     "duration": 1390.732263,
     "end_time": "2025-05-18T13:40:03.600603",
     "exception": false,
     "start_time": "2025-05-18T13:16:52.868340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 13:17:08.909797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747574229.080467      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747574229.134555      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2630a66a2259479386f478476d158661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08a19e38a154f7fabaf20bc79a6966e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/359 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='yiyanghkust/finbert-pretrain', vocab_size=30873, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t5: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbeb43331af94107860c2ebef3bb0891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at yiyanghkust/finbert-pretrain and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456e0968b1c8403c876c0ec51c8afb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for epoch 1: 86.18 seconds\n",
      "Time taken for epoch 1: 168.52 seconds\n",
      "Time taken for epoch 1: 251.16 seconds\n",
      "Time taken for epoch 1: 265.13 seconds\n",
      "Time taken for epoch 2: 83.23 seconds\n",
      "Time taken for epoch 2: 164.46 seconds\n",
      "Time taken for epoch 2: 245.26 seconds\n",
      "Time taken for epoch 2: 259.03 seconds\n",
      "Time taken for epoch 3: 76.70 seconds\n",
      "Time taken for epoch 3: 157.08 seconds\n",
      "Time taken for epoch 3: 236.96 seconds\n",
      "Time taken for epoch 3: 249.87 seconds\n",
      "Total training time: 249.87 seconds\n",
      "Test Accuracy: 0.7352941176470589\n",
      "Test Precision: 0.8\n",
      "Test Recall: 0.6666666666666666\n",
      "Test F1-score: 0.7272727272727272\n",
      "Test ROC-AUC: 0.7395833333333333\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "file_path = '/kaggle/input/fin-csv/Final_Dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['Fraud'] = label_encoder.fit_transform(dataset['Fraud'])\n",
    "\n",
    "# Tokenize the Text Data\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-pretrain')\n",
    "text_data = dataset['Fillings'].tolist()\n",
    "max_length = 512\n",
    "encoded_inputs = tokenizer(text_data, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "attention_masks = encoded_inputs['attention_mask']\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "# Split the Dataset into Training, Validation, and Test Sets\n",
    "train_inputs, temp_inputs, train_labels, temp_labels, train_masks, temp_masks = train_test_split(\n",
    "    encoded_inputs['input_ids'], dataset['Fraud'], attention_masks, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "val_inputs, test_inputs, val_labels, test_labels, val_masks, test_masks = train_test_split(\n",
    "    temp_inputs, temp_labels, temp_masks, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataLoader with attention masks\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels.values).long())\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels.values).long())\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels.values).long())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# Load Pre-trained BERT Model for Sequence Classification\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-pretrain', num_labels=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    start_time = time.time()   # track start time\n",
    "    for batch in train_dataloader:\n",
    "        inputs, masks, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end_time = time.time()   #track end time\n",
    "        epoch_time = end_time - start_time   # Time taken to train the model\n",
    "    \n",
    "        print(f\"Time taken for epoch {epoch+1}: {epoch_time:.2f} seconds\")\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_time = total_end_time - start_time\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "# Evaluation\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, masks, labels = batch\n",
    "        outputs = model(inputs, attention_mask=masks)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "        test_predictions.extend(predictions.tolist())\n",
    "        test_true_labels.extend(labels.tolist())\n",
    "\n",
    "# Metrics for Test Set\n",
    "accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "precision = precision_score(test_true_labels, test_predictions)\n",
    "recall = recall_score(test_true_labels, test_predictions)\n",
    "f1 = f1_score(test_true_labels, test_predictions)\n",
    "roc_auc = roc_auc_score(test_true_labels, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test F1-score:\", f1)\n",
    "print(\"Test ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Training Loop with attention masks\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_predictions = []\n",
    "    train_true_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs, masks, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "        train_predictions.extend(predictions.tolist())\n",
    "        train_true_labels.extend(labels.tolist())\n",
    "    \n",
    "    # Training Metrics\n",
    "    train_accuracy = accuracy_score(train_true_labels, train_predictions)\n",
    "    train_precision = precision_score(train_true_labels, train_predictions)\n",
    "    train_recall = recall_score(train_true_labels, train_predictions)\n",
    "    train_f1 = f1_score(train_true_labels, train_predictions)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {train_loss/len(train_dataloader)}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Training Precision: {train_precision}\")\n",
    "    print(f\"Training Recall: {train_recall}\")\n",
    "    print(f\"Training F1-score: {train_f1}\")\n",
    "    \n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs, masks, labels = batch\n",
    "            outputs = model(inputs, attention_mask=masks)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "            val_predictions.extend(predictions.tolist())\n",
    "            val_true_labels.extend(labels.tolist())\n",
    "    \n",
    "    # Validation Metrics\n",
    "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "    val_precision = precision_score(val_true_labels, val_predictions)\n",
    "    val_recall = recall_score(val_true_labels, val_predictions)\n",
    "    val_f1 = f1_score(val_true_labels, val_predictions)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "    print(f\"Validation Precision: {val_precision}\")\n",
    "    print(f\"Validation Recall: {val_recall}\")\n",
    "    print(f\"Validation F1-score: {val_f1}\\n\")\n",
    "\n",
    "#1. Plot the Confusion Matrix\n",
    "cm = confusion_matrix(test_true_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraudulent\", \"Fraudulent\"])\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Test Data')\n",
    "plt.show()\n",
    "\n",
    "# 2. Plot the ROC Curve\n",
    "fpr, tpr, _ = roc_curve(test_true_labels, test_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='BERT Model')\n",
    "roc_display.plot()\n",
    "plt.title('ROC Curve for Test Data')\n",
    "plt.show()\n",
    "\n",
    "# 3. Plot the Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(test_true_labels, test_predictions)\n",
    "pr_display = PrecisionRecallDisplay(precision=precision_curve, recall=recall_curve)\n",
    "pr_display.plot()\n",
    "plt.title('Precision-Recall Curve for Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f9f65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7451508,
     "sourceId": 11858718,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1394.936066,
   "end_time": "2025-05-18T13:40:03.630465",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T13:16:48.694399",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
